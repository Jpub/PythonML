{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colaboratory를 사용할 때는 다음 주석을 해제하고 실행하기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 다음을 실행하면 authorization code 입력을 요청받습니다.\n",
    "# # 출력된 링크를 클릭하고 Google 계정으로 로그인한 뒤,\n",
    "# # authorization code를 복사해서 붙여 넣습니다.\n",
    "# import os\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working_dir = 'MLSys_100Knocks' #　※※ 여러분이 만든 폴더 경로가 다를 때는 다음을 변경합니다. ※※\n",
    "# path = f'/content/drive/MyDrive/{working_dir}/MainChapter/chapter09'\n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook ipywidgets 활성화\n",
    "# for jupyter notebook (virtualenv 사용 시)\n",
    "#!jupyter nbextension enable --user --py widgetsnbextension\n",
    "\n",
    "# for jupyter lab\n",
    "#!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9장 소규모 머신러닝 시스템을 만드는 테크닉 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 81: 폴더를 만들고 초기 변수를 정의하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = 'data'\n",
    "input_dir = os.path.join(data_dir, '00_input')\n",
    "store_monthly_dir = os.path.join(data_dir, '01_store_monthly')\n",
    "ml_base_dir = os.path.join(data_dir, '02_ml_base')\n",
    "\n",
    "output_ml_result_dir = os.path.join(data_dir, '10_output_ml_result')\n",
    "output_report_dir = os.path.join(data_dir, '11_output_report')\n",
    "\n",
    "master_dir = os.path.join(data_dir, '99_master')\n",
    "model_dir = 'models'\n",
    "\n",
    "os.makedirs(input_dir, exist_ok=True)\n",
    "os.makedirs(store_monthly_dir, exist_ok=True)\n",
    "os.makedirs(ml_base_dir, exist_ok=True)\n",
    "os.makedirs(output_ml_result_dir, exist_ok=True)\n",
    "os.makedirs(output_report_dir, exist_ok=True)\n",
    "os.makedirs(master_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **반드시 데이터와 모델을 폴더에 저장해주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tg_ym = '202104'\n",
    "tg_ym = '202108'\n",
    "\n",
    "target_file = \"tbl_order_\" + tg_ym + \".csv\"\n",
    "m_area_file = 'm_area.csv'\n",
    "m_store_file = 'm_store.csv'\n",
    "store_monthly_file = 'store_monthly_data.csv'\n",
    "ml_base_file = 'ml_base_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 82: 신규 데이터를 로딩하고 매장별 데이터를 만들자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜가 일치합니다\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "m_area = pd.read_csv(os.path.join(master_dir, m_area_file))\n",
    "m_store = pd.read_csv(os.path.join(master_dir, m_store_file))\n",
    "target_data = pd.read_csv(os.path.join(input_dir, target_file))\n",
    "\n",
    "import datetime\n",
    "\n",
    "max_date = pd.to_datetime(target_data[\"order_accept_date\"]).max()\n",
    "min_date = pd.to_datetime(target_data[\"order_accept_date\"]).min()\n",
    "max_str_date = max_date.strftime(\"%Y%m\")\n",
    "min_str_date = min_date.strftime(\"%Y%m\")\n",
    "\n",
    "if tg_ym == min_str_date and tg_ym == max_str_date:\n",
    "    print(f\"날짜가 일치합니다\")\n",
    "else:\n",
    "    raise Exception(f\"날짜가 일치하지 않습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_delta(t):\n",
    "    t1, t2 = t\n",
    "    delta = t2 - t1\n",
    "    return delta.total_seconds() / 60\n",
    "\n",
    "\n",
    "def data_processing(order_data):\n",
    "    order_data = order_data.loc[order_data['store_id'] != 999]\n",
    "    order_data = pd.merge(order_data, m_store, on='store_id', how='left')\n",
    "    order_data = pd.merge(order_data, m_area, on='area_cd', how='left')\n",
    "    order_data.loc[order_data['takeout_flag'] == 0, 'takeout_name'] = 'delivery'\n",
    "    order_data.loc[order_data['takeout_flag'] == 1, 'takeout_name'] = 'takeout'\n",
    "    order_data.loc[order_data['status'] == 0, 'status_name'] = '주문 접수'\n",
    "    order_data.loc[order_data['status'] == 1, 'status_name'] = '결제 완료'\n",
    "    order_data.loc[order_data['status'] == 2, 'status_name'] = '배달 완료'\n",
    "    order_data.loc[order_data['status'] == 9, 'status_name'] = '주문 취소'\n",
    "    order_data.loc[:, 'order_accept_datetime'] = \\\n",
    "        pd.to_datetime(order_data['order_accept_date'])\n",
    "    order_data.loc[:, 'delivered_datetime'] = \\\n",
    "        pd.to_datetime(order_data['delivered_date'])\n",
    "    order_data.loc[:, 'delta'] = order_data[\n",
    "        ['order_accept_datetime', 'delivered_datetime']].apply(calc_delta, axis=1)\n",
    "    order_data.loc[:, 'order_accept_hour'] = \\\n",
    "        order_data['order_accept_datetime'].dt.hour\n",
    "    order_data.loc[:, 'order_accept_weekday'] = \\\n",
    "        order_data['order_accept_datetime'].dt.weekday\n",
    "    order_data.loc[order_data['order_accept_weekday'] >= 5,\n",
    "                   'weekday_info'] = '휴일'\n",
    "    order_data.loc[order_data['order_accept_weekday'] < 5,\n",
    "                   'weekday_info'] = '평일'\n",
    "\n",
    "    store_data = order_data.groupby(['store_name']).count()[['order_id']]\n",
    "    store_f = order_data.loc[\n",
    "        (order_data['status_name'] == \"배달 완료\") |\n",
    "        (order_data['status_name'] == \"결제 완료\")\n",
    "        ].groupby(['store_name']).count()[['order_id']]\n",
    "    store_c = order_data.loc[\n",
    "        order_data['status_name'] == \"주문 취소\"\n",
    "        ].groupby(['store_name']).count()[['order_id']]\n",
    "    store_d = order_data.loc[\n",
    "        order_data['takeout_name'] == \"delivery\"\n",
    "        ].groupby(['store_name']).count()[['order_id']]\n",
    "    store_t = order_data.loc[\n",
    "        order_data['takeout_name'] == \"takeout\"\n",
    "        ].groupby(['store_name']).count()[['order_id']]\n",
    "    store_weekday = order_data.loc[\n",
    "        order_data['weekday_info'] == \"평일\"\n",
    "        ].groupby(['store_name']).count()[['order_id']]\n",
    "    store_weekend = order_data.loc[\n",
    "        order_data['weekday_info'] == \"휴일\"\n",
    "        ].groupby(['store_name']).count()[['order_id']]\n",
    "    times = order_data['order_accept_hour'].unique()\n",
    "    store_time = []\n",
    "\n",
    "    for time in times:\n",
    "        time_tmp = order_data.loc[\n",
    "            order_data['order_accept_hour'] == time\n",
    "            ].groupby(['store_name']).count()[['order_id']]\n",
    "        time_tmp.columns = [f'order_time_{time}']\n",
    "        store_time.append(time_tmp)\n",
    "\n",
    "    store_time = pd.concat(store_time, axis=1)\n",
    "    store_delta = order_data.loc[\n",
    "        order_data['status_name'] != \"주문 취소\"\n",
    "        ].groupby(['store_name']).mean()[['delta']]\n",
    "    store_data.columns = ['order']\n",
    "    store_f.columns = ['order_fin']\n",
    "    store_c.columns = ['order_cancel']\n",
    "    store_d.columns = ['order_delivery']\n",
    "    store_t.columns = ['order_takeout']\n",
    "    store_delta.columns = ['delta_avg']\n",
    "    store_weekday.columns = ['order_weekday']\n",
    "    store_weekend.columns = ['order_weekend']\n",
    "    store_data = pd.concat([\n",
    "        store_data, store_f, store_c, store_d, store_t,\n",
    "        store_weekday, store_weekend, store_time, store_delta], axis=1)\n",
    "    return store_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_name</th>\n",
       "      <th>order</th>\n",
       "      <th>order_fin</th>\n",
       "      <th>order_cancel</th>\n",
       "      <th>order_delivery</th>\n",
       "      <th>order_takeout</th>\n",
       "      <th>order_weekday</th>\n",
       "      <th>order_weekend</th>\n",
       "      <th>order_time_11</th>\n",
       "      <th>order_time_12</th>\n",
       "      <th>...</th>\n",
       "      <th>order_time_14</th>\n",
       "      <th>order_time_15</th>\n",
       "      <th>order_time_16</th>\n",
       "      <th>order_time_17</th>\n",
       "      <th>order_time_18</th>\n",
       "      <th>order_time_19</th>\n",
       "      <th>order_time_20</th>\n",
       "      <th>order_time_21</th>\n",
       "      <th>delta_avg</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가덕해안로점</td>\n",
       "      <td>997</td>\n",
       "      <td>812</td>\n",
       "      <td>185</td>\n",
       "      <td>757</td>\n",
       "      <td>240</td>\n",
       "      <td>699</td>\n",
       "      <td>298</td>\n",
       "      <td>86</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>77</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>97</td>\n",
       "      <td>112</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>34.667488</td>\n",
       "      <td>202108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  store_name  order  order_fin  order_cancel  order_delivery  order_takeout  \\\n",
       "0     가덕해안로점    997        812           185             757            240   \n",
       "\n",
       "   order_weekday  order_weekend  order_time_11  order_time_12  ...  \\\n",
       "0            699            298             86             89  ...   \n",
       "\n",
       "   order_time_14  order_time_15  order_time_16  order_time_17  order_time_18  \\\n",
       "0             96             77             89             84             97   \n",
       "\n",
       "   order_time_19  order_time_20  order_time_21  delta_avg  year_month  \n",
       "0            112             92             80  34.667488      202108  \n",
       "\n",
       "[1 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data = data_processing(target_data)\n",
    "store_data.reset_index(drop=False, inplace=True)\n",
    "store_data.loc[:, 'year_month'] = tg_ym\n",
    "store_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 83: 월별 매장 데이터를 업데이트하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "업데이트 전: 3281건\n",
      "업데이트 후：3281건\n"
     ]
    }
   ],
   "source": [
    "store_monthly_data = pd.read_csv(\n",
    "    os.path.join(store_monthly_dir, store_monthly_file))\n",
    "print(f'업데이트 전: {len(store_monthly_data)}건')\n",
    "store_monthly_data = pd.concat(\n",
    "    [store_monthly_data, store_data], ignore_index=True)\n",
    "store_monthly_data.loc[:, 'year_month'] = \\\n",
    "    store_monthly_data['year_month'].astype(str)\n",
    "store_monthly_data.drop_duplicates(\n",
    "    subset=['store_name', 'year_month'], inplace=True, keep='last')\n",
    "print(f'업데이트 후：{len(store_monthly_data)}건')\n",
    "store_monthly_data.to_csv(\n",
    "    os.path.join(store_monthly_dir, store_monthly_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 84: 머신러닝용 데이터를 만들고 업데이트하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "y = store_monthly_data[\n",
    "    ['store_name', 'year_month', 'order_weekday', 'order_weekend']].copy()\n",
    "y.loc[:, 'one_month_ago'] = pd.to_datetime(y['year_month'], format='%Y%m')\n",
    "y.loc[:, 'one_month_ago'] = y['one_month_ago'].map(\n",
    "    lambda x: x - relativedelta(months=1))\n",
    "y.loc[:, 'one_month_ago'] = y['one_month_ago'].dt.strftime('%Y%m')\n",
    "\n",
    "y_one_month_ago = y.copy()\n",
    "y_one_month_ago.rename(columns={\n",
    "    'order_weekday': 'order_weekday_one_month_ago',\n",
    "    'order_weekend': 'order_weekend_one_month_ago',\n",
    "    'year_month': 'year_month_for_join'}, inplace=True)\n",
    "\n",
    "y = pd.merge(y, y_one_month_ago[[\n",
    "    'store_name', 'year_month_for_join',\n",
    "    'order_weekday_one_month_ago', 'order_weekend_one_month_ago']],\n",
    "             left_on=['store_name', 'one_month_ago'],\n",
    "             right_on=['store_name', 'year_month_for_join'], how='left')\n",
    "\n",
    "y.dropna(inplace=True)\n",
    "y.loc[y['order_weekday'] - y['order_weekday_one_month_ago'] > 0,\n",
    "      'y_weekday'] = 1\n",
    "y.loc[y['order_weekday'] - y['order_weekday_one_month_ago'] <= 0,\n",
    "      'y_weekday'] = 0\n",
    "y.loc[y['order_weekend'] - y['order_weekend_one_month_ago'] > 0,\n",
    "      'y_weekend'] = 1\n",
    "y.loc[y['order_weekend'] - y['order_weekend_one_month_ago'] <= 0,\n",
    "      'y_weekend'] = 0\n",
    "\n",
    "y.rename(columns={'year_month': 'target_year_month'}, inplace=True)\n",
    "y = y[['store_name', 'target_year_month', 'one_month_ago', \n",
    "       'y_weekday', 'y_weekend']].copy()\n",
    "ml_data = pd.merge(y, store_monthly_data,\n",
    "                   left_on=['store_name', 'one_month_ago'],\n",
    "                   right_on=['store_name', 'year_month'],\n",
    "                   how='left')\n",
    "\n",
    "del ml_data[\"target_year_month\"]\n",
    "del ml_data[\"one_month_ago\"]\n",
    "ml_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_base_data = pd.read_csv(os.path.join(ml_base_dir, ml_base_file))\n",
    "print(f'변경 전：{len(ml_base_data)}건')\n",
    "ml_base_data = pd.concat([ml_base_data, ml_data], ignore_index=True)\n",
    "ml_base_data.loc[:, 'year_month'] = ml_base_data['year_month'].astype(str)\n",
    "ml_base_data.drop_duplicates(\n",
    "    subset=['store_name', 'year_month'], inplace=True, keep='last')\n",
    "print(f'변경 후：{len(ml_base_data)}건')\n",
    "ml_base_data.to_csv(os.path.join(ml_base_dir, ml_base_file), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 85: 머신러닝 모델용 사전 데이터를 가공하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data = pd.get_dummies(ml_base_data['store_name'], \n",
    "                               prefix='store', prefix_sep='_')\n",
    "del category_data['store_가덕해안로점']\n",
    "del ml_base_data['year_month']\n",
    "del ml_base_data['store_name']\n",
    "ml_base_data = pd.concat([ml_base_data, category_data], axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(ml_base_data, \n",
    "                                         test_size=0.3, random_state=0)\n",
    "print(f'Train：{len(train_data)}건/ Test:{len(test_data)}')\n",
    "print(f'Weekday Train0：{len(train_data.loc[train_data[\"y_weekday\"] == 0])}건')\n",
    "print(f'Weekday Train1：{len(train_data.loc[train_data[\"y_weekday\"] == 1])}건')\n",
    "print(f'Weekday Test0：{len(test_data.loc[test_data[\"y_weekday\"] == 0])}건')\n",
    "print(f'Weekday Test1：{len(test_data.loc[test_data[\"y_weekday\"] == 1])}건')\n",
    "\n",
    "print(f'Weekend Train0：{len(train_data.loc[train_data[\"y_weekend\"] == 0])}건')\n",
    "print(f'Weekend Train1：{len(train_data.loc[train_data[\"y_weekend\"] == 1])}건')\n",
    "print(f'Weekend Test0：{len(test_data.loc[test_data[\"y_weekend\"] == 0])}건')\n",
    "print(f'Weekend Test1：{len(test_data.loc[test_data[\"y_weekend\"] == 1])}건')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 86: 머신러닝 모델을 구현하고 평가하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_and_eval(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    tn_train, fp_train, fn_train, tp_train = \\\n",
    "        confusion_matrix(y_train, y_pred_train).ravel()\n",
    "    tn_test, fp_test, fn_test, tp_test = \\\n",
    "        confusion_matrix(y_test, y_pred_test).ravel()\n",
    "    score_train = pd.DataFrame({\n",
    "        'DataCategory': ['train'], 'acc': [acc_train], 'f1': [f1_train],\n",
    "        'recall': [recall_train], 'precision': [precision_train],\n",
    "        'tp': [tp_train], 'fn': [fn_train], 'fp': [fp_train], 'tn': [tn_train]})\n",
    "    score_test = pd.DataFrame({\n",
    "        'DataCategory': ['test'], 'acc': [acc_test], 'f1': [f1_test],\n",
    "        'recall': [recall_test], 'precision': [precision_test],\n",
    "        'tp': [tp_test], 'fn': [fn_test], 'fp': [fp_test], 'tn': [tn_test]})\n",
    "    score = pd.concat([score_train, score_test], ignore_index=True)\n",
    "    importance = pd.DataFrame(\n",
    "        {'cols': X_train.columns, 'importance': model.feature_importances_})\n",
    "    importance = importance.sort_values('importance', ascending=False)\n",
    "    cols = pd.DataFrame({'X_cols': X_train.columns})\n",
    "    display(score)\n",
    "    return score, importance, model, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, \\\n",
    "    precision_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pickle\n",
    "\n",
    "X_cols = list(train_data.columns)\n",
    "X_cols.remove('y_weekday')\n",
    "X_cols.remove('y_weekend')\n",
    "targets_y = ['y_weekday', 'y_weekend']\n",
    "\n",
    "target_output_dir_name = f'results_{tg_ym}'\n",
    "target_output_dir = os.path.join(output_ml_result_dir, target_output_dir_name)\n",
    "os.makedirs(target_output_dir, exist_ok=True)\n",
    "print(target_output_dir)\n",
    "\n",
    "score_all = []\n",
    "importance_all = []\n",
    "\n",
    "for target_y in targets_y:\n",
    "    y_train = train_data[target_y]\n",
    "    X_train = train_data[X_cols]\n",
    "    y_test = test_data[target_y]\n",
    "    X_test = test_data[X_cols]\n",
    "\n",
    "    models = {'tree': DecisionTreeClassifier(random_state=0),\n",
    "              'RandomForest': RandomForestClassifier(random_state=0),\n",
    "              'GradientBoosting': GradientBoostingClassifier(random_state=0)}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(model_name)\n",
    "        score, importance, model, cols = make_model_and_eval(\n",
    "            model, X_train, X_test, y_train, y_test)\n",
    "        score['model_name'] = model_name\n",
    "        importance['model_name'] = model_name\n",
    "        score['model_target'] = target_y\n",
    "        importance['model_target'] = target_y\n",
    "\n",
    "        model_nema = f'model_{target_y}_{model_name}.pickle'\n",
    "        model_path = os.path.join(target_output_dir, model_nema)\n",
    "        with open(model_path, mode='wb') as f:\n",
    "            pickle.dump(model, f, protocol=2)\n",
    "        score_all.append(score)\n",
    "        importance_all.append(importance)\n",
    "\n",
    "score_all = pd.concat(score_all, ignore_index=True)\n",
    "importance_all = pd.concat(importance_all, ignore_index=True)\n",
    "cols = pd.DataFrame({'X_cols': X_train.columns})\n",
    "score_name = 'score.csv'\n",
    "importance_name = 'importance.csv'\n",
    "cols_name = 'X_cols.csv'\n",
    "score_path = os.path.join(target_output_dir, score_name)\n",
    "importance_path = os.path.join(target_output_dir, importance_name)\n",
    "cols_path = os.path.join(target_output_dir, cols_name)\n",
    "score_all.to_csv(score_path, index=False)\n",
    "importance_all.to_csv(importance_path, index=False)\n",
    "cols.to_csv(cols_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 87: 신규 데이터 예측을 위한 준비를 하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data = pd.get_dummies(store_data['store_name'], \n",
    "                               prefix='store', prefix_sep='_')\n",
    "del category_data['store_가덕해안로점']\n",
    "store_data = pd.concat([store_data, category_data], axis=1)\n",
    "\n",
    "X_cols_name = 'X_cols.csv'\n",
    "X_cols = pd.read_csv(os.path.join(model_dir, X_cols_name))\n",
    "X_cols = X_cols['X_cols']\n",
    "\n",
    "X = store_data[X_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weekday_name = 'model_y_weekday_GradientBoosting.pickle'\n",
    "model_weekend_name = 'model_y_weekend_GradientBoosting.pickle'\n",
    "\n",
    "model_weekday_path = os.path.join(model_dir, model_weekday_name)\n",
    "model_weekend_path = os.path.join(model_dir, model_weekend_name)\n",
    "\n",
    "with open(model_weekday_path, mode='rb') as f:\n",
    "    model_weekday = pickle.load(f)\n",
    "    \n",
    "with open(model_weekend_path, mode='rb') as f:\n",
    "    model_weekend = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 88: 신규 데이터를 예측하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weekday = model_weekday.predict(X)\n",
    "pred_weekend = model_weekend.predict(X)\n",
    "pred_proba_weekday = model_weekday.predict_proba(X)[:, 1]\n",
    "pred_proba_weekend = model_weekend.predict_proba(X)[:, 1]\n",
    "pred = pd.DataFrame({'pred_weekday': pred_weekday, \n",
    "                     'pred_weekend': pred_weekend,\n",
    "                     'score_weekday': pred_proba_weekday, \n",
    "                     'score_weekend': pred_proba_weekend})\n",
    "pred.loc[:, 'store_name'] = store_data['store_name']\n",
    "pred.loc[:, 'year_month'] = tg_ym\n",
    "pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 89: 현장용 보고서를 만들어 출력하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [\n",
    "    'store_name', 'order', 'order_fin', 'order_cancel', 'order_delivery',\n",
    "    'order_takeout', 'order_weekday', 'order_weekend', 'delta_avg']\n",
    "store_data = store_data[target_cols]\n",
    "actual_cols = ['store_name']\n",
    "rename_cols = [x + f'_{tg_ym}'\n",
    "               for x in store_data.columns if x != 'store_name']\n",
    "actual_cols.extend(rename_cols)\n",
    "store_data.columns = actual_cols\n",
    "store_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.loc[pred['score_weekday'] >= 0.75, '주문 예측/평일'] = '증가(큼)'\n",
    "pred.loc[(pred['score_weekday'] < 0.75) &\n",
    "         (pred['score_weekday'] >= 0.5), '주문 예측/평일'] = '증가'\n",
    "pred.loc[(pred['score_weekday'] < 0.5) &\n",
    "         (pred['score_weekday'] >= 0.25), '주문 예측/평일'] = '감소'\n",
    "pred.loc[pred['score_weekday'] < 0.25, '주문 예측/평일'] = '감소(큼)'\n",
    "\n",
    "pred.loc[pred['score_weekend'] >= 0.75, '주문 예측/휴일'] = '증가(큼)'\n",
    "pred.loc[(pred['score_weekend'] < 0.75) &\n",
    "         (pred['score_weekend'] >= 0.5), '주문 예측/휴일'] = '증가'\n",
    "pred.loc[(pred['score_weekend'] < 0.5) &\n",
    "         (pred['score_weekend'] >= 0.25), '주문 예측/휴일'] = '감소'\n",
    "pred.loc[pred['score_weekend'] < 0.25, '주문 예측/휴일'] = '감소(큼)'\n",
    "\n",
    "report = pred[['store_name', '주문 예측/평일', '주문 예측/휴일',\n",
    "               'score_weekday', 'score_weekend']]\n",
    "report = pd.merge(report, store_data, on='store_name', how='left')\n",
    "\n",
    "pred_ym = datetime.datetime.strptime(tg_ym, '%Y%m')\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "pred_ym = pred_ym + relativedelta(months=1)\n",
    "pred_ym = datetime.datetime.strftime(pred_ym, '%Y%m')\n",
    "\n",
    "report_name = f'report_pred_{pred_ym}.xlsx'\n",
    "print(report_name)\n",
    "report.to_excel(os.path.join(output_report_dir, report_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **다음 테크닉를 진행하기 전 테크닉 81의 `tg_ym`을 `202105`, `202106`, `202107`, `202108`로 순서대로 지정하고 실행하십시오**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테크닉 90: 머신러닝 모델의 정밀도 추이를 시각화하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ml_results_dirs = os.listdir(output_ml_result_dir)\n",
    "score_all = []\n",
    "for ml_results_dir in ml_results_dirs:\n",
    "    score_file_path = os.path.join(output_ml_result_dir, \n",
    "                                   ml_results_dir, 'score.csv')\n",
    "    score_monthly = pd.read_csv(score_file_path)\n",
    "    score_monthly['dirs'] = ml_results_dir\n",
    "    score_all.append(score_monthly)\n",
    "score_all = pd.concat(score_all, ignore_index=True)\n",
    "score_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_all_gb = score_all.loc[\n",
    "    (score_all['model_name'] == 'GradientBoosting') &\n",
    "    (score_all['DataCategory'] == 'test')]\n",
    "model_targets = score_all_gb['model_target'].unique()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for model_target in model_targets:\n",
    "    view_data = score_all_gb.loc[\n",
    "        score_all_gb['model_target'] == model_target]\n",
    "    plt.scatter(view_data['dirs'], view_data['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
