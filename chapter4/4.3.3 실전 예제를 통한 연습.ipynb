{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T15:23:14.692575Z",
     "start_time": "2021-08-06T15:23:13.229578Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "from math import log2\n",
    "from sklearn import tree\n",
    "import pydot\n",
    "def split_dataset(dataset, classes, feat_idx):\n",
    "    ''' 어떤 특징 및 특정값을 기반으로 데이터셋 분할\n",
    "    :param dataset: 분할할 데이터셋\n",
    "    :param classes: 데이터셋에 대응하는 클래스. 데이터셋 길이와 동일함\n",
    "    :param feat_idx: 특성 벡터 중에 특성 인덱스\n",
    "    :param splited_dict: 분할 후 데이터의 딕셔너리 값\n",
    "    '''\n",
    "    splited_dict = {}\n",
    "    for data_vect, cls in zip(dataset, classes):\n",
    "        feat_val = data_vect[feat_idx]\n",
    "        sub_dataset, sub_classes = splited_dict.setdefault(feat_val, [[], []])\n",
    "        sub_dataset.append(data_vect[: feat_idx] + data_vect[feat_idx + 1:])\n",
    "        sub_classes.append(cls)\n",
    "        return splited_dict\n",
    "\n",
    "def get_majority(classes):\n",
    "    ''' 비중이 가장 높은 클래스를 반환\n",
    "    '''\n",
    "    cls_num = defaultdict(lambda: 0)\n",
    "    for cls in classes:\n",
    "        cls_num[cls] += 1\n",
    "        return max(cls_num, key=cls_num.get)\n",
    "\n",
    "def get_shanno_entropy(values):\n",
    "    ''' 섀넌 엔트로피 계산\n",
    "    '''\n",
    "    uniq_vals = set(values)\n",
    "    val_nums = {key: values.count(key) for key in uniq_vals}\n",
    "    probs = [v/len(values) for k, v in val_nums.items()]\n",
    "    entropy = sum([-prob*log2(prob) for prob in probs])\n",
    "    return entropy\n",
    "\n",
    "def choose_best_split_feature(dataset, classes):\n",
    "    ''' 정보 이득을 기반으로 데이터의 최적 특징 분할\n",
    "    :param dataset: 데이터셋\n",
    "    :param classes: 클래스(레이블)\n",
    "    :return: 정보 이득이 가장 큰 인덱스 반환\n",
    "    '''\n",
    "    base_entropy = get_shanno_entropy(classes)\n",
    "    feat_num = len(dataset[0])\n",
    "    entropy_gains = []\n",
    "    for i in range(feat_num):\n",
    "        splited_dict = split_dataset(dataset, classes, i)\n",
    "        new_entropy = sum([\n",
    "            len(sub_classes) / len(classes) * get_shanno_entropy(sub_classes)\n",
    "            for _, (_, sub_classes) in splited_dict.items()\n",
    "        ])\n",
    "        entropy_gains.append(base_entropy - new_entropy)\n",
    "    return entropy_gains.index(max(entropy_gains))\n",
    "\n",
    "def create_tree(dataset, classes, feat_names):\n",
    "    ''' 현재 데이터셋에 기반해 의사결정 트리를 재귀적으로 만듦\n",
    "    :param dataset: 데이터셋\n",
    "    :param feat_names: 특성\n",
    "    :param classes: 클래스\n",
    "    :param tree: 딕셔너리 형식으로 트리를 반환\n",
    "    '''\n",
    "    # 만약 데이터에 한 가지 클래스만 존재한다면 멈춤\n",
    "    if len(set(classes)) == 1:\n",
    "        return classes[0]\n",
    "    # 모든 특성을 탐색한 후 가장 많은 클래스를 반환\n",
    "    if len(feat_names) == 0:\n",
    "        return get_majority(classes)\n",
    "    # 새로운 서브트리 생성\n",
    "    tree = {}\n",
    "    best_feat_idx = choose_best_split_feature(dataset, classes)\n",
    "    feature = feat_names[best_feat_idx]\n",
    "    tree[feature] = {}\n",
    "    # 서브 트리 생성에 필요한 서브 데이터셋 생성\n",
    "    sub_feat_names = feat_names[:]\n",
    "    sub_feat_names.pop(best_feat_idx)\n",
    "    splited_dict = split_dataset(dataset, classes, best_feat_idx)\n",
    "    for feat_val, (sub_dataset, sub_classes) in splited_dict.items():\n",
    "        tree[feature][feat_val] = create_tree(sub_dataset, sub_classes, sub_feat_names)\n",
    "        tree = tree\n",
    "        feat_names = feat_names\n",
    "        return tree\n",
    "def build_decisiontree_using_sklearn(X, Y):\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf = clf.fit(X, Y)\n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    feature = clf.tree_.feature\n",
    "    threshold = clf.tree_.threshold\n",
    "    dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "    graph = pydot.graph_from_dot_data(dot_data)\n",
    "    print(n_nodes)\n",
    "    print(children_left)\n",
    "    print(children_right)\n",
    "    print(feature)\n",
    "    print(threshold)\n",
    "    graph[0].write_dot('iris_simple.dot')\n",
    "    graph[0].write_png('iris_simple.png')\n",
    "    return clf\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lense_labels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open('data/decisiontree/lenses_num.txt', 'r', encoding = 'utf-8-sig') as f:\n",
    "        for line in f:\n",
    "            comps = line.strip().split(', ')\n",
    "            X.append(comps[: -1])\n",
    "            Y.append(comps[-1])\n",
    "    dt_model = build_decisiontree_using_sklearn(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
